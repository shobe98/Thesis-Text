\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage{helvet}
\usepackage{tikz}
\usepackage{multirow}
\usepackage{caption}
\usepackage{array}
\usepackage{subcaption}
\usepackage[section]{placeins}
\usepackage[acronym]{glossaries}
\usepackage{setspace}
\usepackage{subfiles}
\usepackage{tikz}


\usepackage{hyperref}
\hypersetup{
    colorlinks=false,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
}


\title{%
    mRNA Isoform Loci Prediction from RNA Sequencing Experiments \\
    \large Thesis Proposal}

\author{Andrei Stanciu}
\date{December 2020}\date{December 2020}




\makeglossaries

\doublespacing
\begin{document}

\maketitle

\section{Introduction}


\subsection{History}
Genetic sequencing has seen an astonishing development in availability and processing power in the past century
\cite{Hood2003}. Only in 1953, Watson and Crick \cite{WATSON1953} proposed the now well known double helix structure of DNA. Soon after, in 1977, Maxam and Gilbert \cite{Maxam1977} described a method of sequencing DNA. Back then, it took Sanger et al. \cite{Sanger1977} roughly one year to sequence the genome of a virus, consisting of 5,375 nucleotides. By 1986, Smith et al. \cite{Smith1986} showcased a tool that would sequence roughly 250 nucleotides an hour. 

At the same time, in the 1940s and the 1950s the precursors of modern day computers were being created. Since then, the computing power increased at an exponential rate, as predicted by Moore \cite{Moore2006}. Together with the computing speed also grew the DNA sequencing throughput. While the Human Genome Project took 10 years to complete, Illumina Sequencing \cite{illuminaSeq} was sequencing 18000 human genomes in 2014. This series of breakthroughs serve as the foundation of what is now the 'genomic era', where the average researcher has access to myriads of genomic data sets and have the power to process them on their personal computers.   

\subsection{Biological Background}
The DNA holds a series of properties that make it suitable for digital analysis. A DNA molecule consists of two chains of nucleotides, also called strands. In turn, a strand of DNA is a series of  base pairs - adenine (A), cytosine (C), guanine (G) and thymine (T), which could come in any combination. These sequences of basepairs encode instructions for making the molecules that support life. 


Due to its underlying chemistry, the strand of DNA has two distinct ends called the 5' end and the 3' end, being oriented from the 5' end to the 3'end. Additionally, each nucleotide from one strand pairs with a corresponding nucleotide from the opposite strand. Thus, adenine (A) pairs with thymine (T) and cytosine (C) pairs with guanine (G). This, together with the fact that the two strands of the helix run in opposite (anti parallel) directions, produces for every sequence of DNA a reverse complement sequence. 

Sequences of DNA are copied (transcribed) to RNA and transported outside the nucleus. The RNA is a single stranded chain of nucleotides where Thymine (T) is replaced by Uracil (U). If the RNA holds instructions for making protein it is called \gls{mrna}. Even if only a small fraction of the human DNA codes for proteins, it is now believed that more than 90\% of the human genome gets transcribed \cite{Pertea2012}. Transcription itself is a highly regulated cellular process, responding to various cellular and extracellular signals\cite{Hahn2011}. This gives that the number of \acrshort{mrna}s inside the cell varies significantly from gene to gene, and from cell to cell. The collection of all mRNAs in a cell, called a transcriptome, define the identity of a cell in multi cellular organisms. 

\subsection{Gene Translation}
Inside the cell the \acrshort{mrna} gets translated into protein. This itself is a highly complex and highly regulated process. The basepairs in an \acrshort{mrna} are grouped in nonoverlapping sequences of 3 nucleotides, called codons. 61 of the possible codons code for a aminoacid, while 3 of them represent a stop codon. Ribosomes - macromomolecular machines consisting of ribosomal RNA and ribosomal proteins - bind to the mRNA and use the information in it to build the appropriate protein, aminoacid by aminoacid. A lot of the complexity and regulation of translation comes from the fact that the beginning and end of a protein are marked by a start and stop codon on the mRNA. Since the mRNA strands are oriented from their 5' end to their 3' end, the region before the start codon on an mRNA is called 5'\gls{utr} and the region following the stop codon is called 3'\acrshort{utr}. The region spanning  between the two codons, which codes for a protein, is  called \gls{utr}. Thus the ribosome buynd to the mRNA has to scan the 5'UTR until it identifies the AUG (start) codon. This codon signals the ribosome to start building the protein. 

\begin{enumerate}
    \item full details of ribosome translating? 
    \item Factors that influence translation
    \item An example of uORFs and how their expression affects the translation of the gene. [what was the canonical example for this?]
    \item significance of mRNA isoform variety in gene translation
\end{enumerate}

\subsection{RNASeq}
    Understanding and comparing the transcriptomes of different cells under different conditions offers sceintists a plethora of new insights. [give examples from papers]. With the wide availability of high throughput sequencing it is now possible to sequence all the RNA  present in an experiment\cite{Kukurba2015}. In the current technological era, such an mRNA experiment usually gives information about millions of basepairs present in a cell. 
    
    One common sequencing protocol is the Illumina sequencing. It excels at sequencing relatively short mRNA fragments (on the order of hundreds of nucleotides per fragment). [needs quotations] The way these experiments are prepared and sequenced involve multiple steps which each can indroduce a specific bias. In the case of Illumina sequencing, a biological sample often consists of multiple cells with the same condition. The cells in the sample are broken apart to expose the mRNAs and the mRNAs are filtered out. The purified mRNA subsequently gets broken up in smaller fragments. There are different methods available for fragmentation depending on the experimental design and desired outcomes. The fragmented mRNAs are then reverse transcribed to complementary DNA (cDNA), which is augumented with adapters and barcodes. [What is the purpose of the adapter?]. The barcodes serve as a unique identifier for the experiment. In the case multiple experiments are sequenced at the same time, the barcodes are used to tell which read comes from which experiment. Subsequently, a PCR [citation? details?] reaction amplifies the number of present fragments by making millions [?] of copies of each fragment. [What's the purpose of this? Is it to give us more confidence in the reads] [to be continued]   
    
    An additional variation in sequencing methodology comes from paired end versus single end reads. Single end reads are sequences of RNA read from one of the fragments described above. Based on the technology used [citation], for each fragment sequenced there is exactly one single end read. In the case of paired end reads, the RNA fragment is sequenced twice, once from each end. This gives two different reads. The sequencer imposes some limits on the length of the reads, and thus, the selected length of fragments influences the downstream possibilities of analysis. If the selected length is short enough, it is very likely that the two paired reads will overlap. This increases the confidence in each one of the reads. If the length of RNA is larger than twice the sequencing length, it becomes unlikely the two ends will overlap. This later option gives an ordering between pairs of reads and can be used for \textit{de novo} transcriptome assembly \cite{Hlzer2019}.
    
    Another widely used application of RNASeq is ribosome profiling, proposed by Ingolia et al \cite{Ingolia2012}. By "freezing" in place translating ribosomes one can extract and isolate the mRNA fragments which the ribosome was protecting.These ribosome-protected fragments can later be sequenced. Together with an appropriate dataset of mRNA fragments, one can quantify how efficiently a gene is translated (ribosomes / mRNA fragments). This method can be used to understand how different conditions affect translation [citation], to identify novel genes or identify upstream Open Reading Frames (u\acrshort{orf}s) - reading frames that occur before the 5' start of a canonical \gls{ORF}.
    
    
\begin{enumerate}
    \item Quick intro on the biological preps: cells, mRNA isolation, fragmentation, PCR: note that these process introduce biases in which data gets sequenced
    \item general methods for sequencing
    \item paired end versus single end
    \item ribosome profiling
    \item our data
    \item Steinmetz RNASeq data
    \item note how much variety is in  RNASeq experiments and methods. 
\end{enumerate}

\subsection{Isoforms}
It is often assumed, for simplicity, that the mRNAs coming from a gene have a similar form. In fact, many genes are known to have various isoforms - slight variation in length or in splicing - especially in more complex organisms. Understanding these variety of these isoforms could help us gain a more in depth understanding on regulatory mechanisms. Known regions of the genome, called introns, lie completely inside a gene's boundary and get removed from the final mRNA. This event is called splicing. For genes that contain introns, there are multiple ways to conduct splicing, which depends on whether introns are removed or not, and at times, whether the regions between introns are kept or not. These alternative splicing variants of mRNA result in similar proteins with variations in function, called protein isoforms. [more details? examples?] 
While for each protein isoform there exists an mRNA isoform that generated it, there can be different mRNA isoforms producing the same protein. This is mainly because the mRNA has two regions, the 5'\acrshort{utr} and the 3'\acrshort{utr}, that do not get translated into protein. Thus, any variation in length between two mRNAs beyond the \gls{cds} result into two different isoforms. Understanding these variety of these isoforms could help us gain a more in depth understanding on regulatory mechanisms. For instance, a recent study \cite{Shamir2020} showed that the relative distribution of two isoforms of STAT3 directly influences the expression of a gene correlated with COVID-19 infection. 

Since the 5'\acrshort{utr} of an mRNA impacts the way a gene is translated through structure and uORFs, understanding the relative distribution of these mRNA isoforms has the potential of providing new insight into gene translation regulation. [more details] While there is significant research in analysing specific protein isoforms, the current methods of analysing isoforms across the whole genome are limited.  It is worth mentioning that there are some alternative methods for identifying isoforms. For instance, UNAGI\cite{Alkadi2020} outperforms the Illumina pipeline when it comes to identifying novel transcripts and does slightly better when it comes to identifying isoforms. 

Our chosen model organism for implementing and testing isoform prediction is Sacharomyces Cerevisiae, since it is extensively studied and many genes in more complex organisms have homologs in yeast. To show that for each gene the divisions between the three regions (5'\acrshort{utr}, \acrshort{cds}, 3'\acrshort{utr}) are not fixed, Pelechano and Steinmetz \cite{Pelechano2013} have shown that S. cerevisiae presents an extensive level of heterogeneity in its transcriptome. In simpler terms, there is variability in the lengths of the 5’UTR and the 3’UTR. Unfortunately, Both Alkadi et al. \cite{Alkadi2020} and Pelechano et al. \cite{Pelechano2013} require long reads of cDNA - a more complicated library preparation than the one needed for \acrshort{rnaseq}. Thus, \acrshort{rnaseq} holds the potential of making isoform analysis accessible and accurate, without extra lab experimentation needed. The tool proposed in this paper is a digital solution which can be run on old \acrshort{rnaseq} experiments, conveying new insights. Nonetheless, in the case of RNASeq experiments, it is nontrivial to know from which isoform each short read comes, especially given that these isoforms are present in various distributions under different conditions. 

[reorganize this section]

\subsection{Previous research/Literature review}
[papers on isoform analysis]

\subsection{mRNA Isoform  identification }
[Main goal of our tool]
\subsubsection{TODO list}

[Maybe use the figure from here as an example http://shadarf.blogspot.com/2017/07/how-to-make-reverse-complement-of-dna.html]


\subsection{Introduction Outline}
\begin{enumerate}
    \item Introduction on the basic biology: From DNA to mRNA to protein
    \item Background on transcription 
    \item Introduce yeast as a model organism
    \item Genome annotations
    \item Introduce RNASequencing
    \item Present general methods for RNASeq
    \item Present Ingolia methods for RNASeq and introduce our datasets
    \item Introduce translation regulation. this is why we're trying to identify mRNA isoforms (in 5'UTR)
    \item Describe what isoforms are 
    \item Introduce the problem raised by steinmetz et el (new discoveries on yeast heterogeneity) 
    \item Talk about existing research on isoform analysis 
    \item Motivation behind using RNASeq to identify isoforms
    \item Present the main idea of the tool
    \item Present  the additional tools that resulted as a side effect from developing the main tool

\end{enumerate}

Punchline: \\

This study proposes a suite of software tools that use machine learning models to identify novel protein isoforms from \gls{rnaseq} Data. The suite also comes with a series of data processing and visualisation pipelines that are meant to help identifying new or miss annotated genes. In order to facilitate this, we provide a standalone in-silico data generation pipeline which produces novel RNASeq libraries informed by expected isoform distributions. 

\section{Methods}
\subsection{Datasets}\label{datasets}

The main datasets used to run experiments are a series of eight \acrshort{rnaseq} experiments conducted as part of an ongoing study {\tiny[TODO: find a way to cite our experiments]}. These are coming from four biological conditions: two wildtype strains of S. Cerevisiae and two mutants, each coming in two replicates. In addition to these, we will use a list of the gene isoforms found by Pelechano et al. \cite{Pelechano2013}. The same study \cite{Pelechano2013} used a separate \cite{Wilkening2013}  \acrshort{rnaseq} experiment as a benchmark for their findings. Given that we are using the isoform annotations from Pelechano et al. \cite{Pelechano2013}, we attempted replicating their \acrshort{rnaseq} experiment. Unfortunately, due to different versions of tools available, replicating the \acrshort{rnaseq} experiment became a difficult task. For more details see the Discussion (\ref{disc}) section. 

\subsection{mRNA pre-processing}
Processing a \acrshort{rnaseq} experiment takes a significant number of intermediary steps. In the case of the \textit{in vivo} data we are using, the mRNA fragment size was selected to be between 30 and 60 nucleotides long. We used \textit{fastx\_clipper} to remove the standard adapter from the single end reads anad \textit{fastx\_trimmer}  to trimm the first nucleotide of each read and cap the read length to 45nt. Using \textit{bowtie2} we aligned all the reads against a library of ribosomal RNA and discarded all the reads that  contained rRNA. Finally, using $tophat$ we aligned the mRNA fragments to the reference genome. Finally, the aligned files, in \textit{bam} format, are indexed using \textit{SAM tools}. We used the local cluster computer which runs a Ubuntu/Debian [Give accurate details] distribution and uses the $SLURM$ workload manager. A flow chart of the data pre-processing can be found in Figure \ref{preprocessing}. All of the scripts used, the annotations and the index files can be found here. [link]


\subfile{flowchart.tex}

\subsection{Preliminary Analysis}
\subsubsection{Read density}\label{density}
The fundamental data structure used in this study is a read density array. For a genomic region of interest it stores the number of reads in an experiment that have aligned to every position. Plotting the values of a read density allows us to get an intuition on the patterns of transcription in a particular experiment, to highlight transcribed regions and to compare them. One important use case in further downstream analysis is looking at the read density around a particular position. An example of this structure can be found in Figure \ref{density} .Thus, an interval query on this structure is "Given an existing RNASeq experiment, What is the read density array in the range $[a...b]$ in the genome?" 
This prompts us to implement a structure that supports queries for intervals in an efficient manner. One bottleneck in processing large RNASeq files is reading and iterating through all the reads in the file. This process is slow even when the bam file is indexed. Thus, any naive method that would go through the aligned reads for each query would be too slow. Given that S. Cerevisae's genome is relatively small compared to others (12MB vs 3GB for humans), one can hold into memory the read density across the whole genome.

Thus, the data structure used to represent read density is an array of integers, with $density[i]$ meaning the number of RNA reads that have aligned to position $i$ in the genome. Instead of iterating through all the positions inside a fragment and incrementing the density, I opted for a faster approach. 


\subfile{read_density_fig.tex}
\begin{center}
Let $start(i) =$ the number of reads that start at position $i$ in the genome \\
Let $end(i) =$ the number of reads that end at position $i$ in the genome \\
($i-1$ is the last position the fragment covers) \\
Let $\delta(i) = start(i) - end(i)$ \\
This gives that $density[i] = \sum\limits_{j=0}^i \delta[i]$ \\
Finally, $Query(a, b) = density[a:b]$

\end{center}

[Should I give algorithm pseudocode?]
[proof of correctness?]
[details on complexity/efficiency?]

\subsubsection{Metagene Analysis}\label{metagene_sect}
A different analysis strategy was inspired by our hypothesis and uses heavily the read density data structure described in Section \ref{density}. The reads that aligned to a particular region are coming from different copies of the mRNA. Not only there are multiple copies of each mRNA but also, these copies can come from different isoforms. The question that arises from this is "can the presence of different mRNA isoforms be identified from the read density alone?". We think yes and here is our hypothesis. For a gene with two isoforms, we expect to see a significant increase in the density right after the beginning of the shorter isoform. This is because the two isoforms overlap the same \acrshort{cds}, and since one is shorter than the other one, its 5'\acrshort{utr} should be completely included in the longer one's 5'\acrshort{utr}. Thus, any read aligned with the gene after the junction can be from either isoform, while a read aligned with the gene between the beginning of the long isoform and the junction must come from the longer isoform. Figure \ref{twoisoforms} shows a randomly generated read distribution that comes from two different isoforms of the same gene. For an example see Figure \ref{twoisoform}. 

\subfile{two-isoform-fig.tex}

To validate this hypothesis, we implemented a metagene analysis method to look at all isoform junctions at once. We define an isoform junction as the position (inside the 5'UTR of a gene) where a shorter isoform begins. This restricts our dataset to genes that have at least two isoforms. If a gene has $n$ isoforms that differ in 5'UTR length, we obtain $n - 1$ isoform junctions. The differences in read density around isoform can often be overlook because of noise in the data, high frequency of isoform junctions in a relatively small region or low relative distribution between isoforms (for more details on this see the discussion section (\ref{disc})). We believe that aggregating all the densities around known isoform junctions will amplify any local effect in the individual densities. Thus, we define a window of interest (usually -50nt to +50nt around a junction) and we look at the read density in that region. Adding up the densities for all points of interest (isoform junctions) will produce a metagene plot. A simplified example of this can be seen in Figure \ref{metagene}. The algorithm can be easily applied to different scenarios by selecting different sets of points of interest or changing the size of the window. 
We used the isoforms identified by Pelechano et al. \cite{Pelechano2013} to define known isoforms junctions and we inspected the datasets described in section \ref{datasets}. In addition to that we naively picked the same number of random positions in the 5'UTRs of genes to be candidates for a control group. Thus, visualising the metagene plot for all the known isoform junctions in contrast to the metagene for the control group gives supporting arguments to our hypothesis. The main observation is that the metagene of isoform junctions sees a significant increase around the positions of interest. 
Thus, define $S$ to be a set of genomic positions of interest. To avoid having overlapping data we randomly selected on junction from each gene containing more than one annotated isoform.  
To quantify the significance of this observation we define a metric $\delta_n(S)$ for the set $S$ of isoform junctions $\delta_n(S) = metagene(S)[+n] / metagene(S)[-n]$ - the ratio between cummulated read densities $n$ basepairs downstream from any point in $S$ and $n$ basepairs upstream. We generated $10000$ control groups $R_i, i \in [1...10000]$. We took advantage of the large computational power at our disposal and with every iteration we selected the elements of $S$ again, thus generating a collection of sets $S_i$ where each set contains a junction from every gene. Set $S_i$ and $S_j$ will consider different junction candidates from the same gene. We varied $n$ between $1$ and $100$ and computed $\delta_n(R_i)$ and $\delta_n(S_i)$. With this large amount of simulation data, one can generate the sampling distributions of $\delta(n)$ under different conditions. This allows us to run a paired Kolmogorov-Smirnov \cite{Massey1951} statistical test and verify our hypothesis. 

\subfile{meta-fig.tex}

\subsection{\textit{in silico} Data Generation}

In order to verify that read density data holds relevant information for identifying isoform distribution, we implemented a tool that generates random reads informed by randomly generated isoform distribution. The first prototype of data generation starts from the existing annotated CDSes in the genome. For each CDS, we randomly fix the number of 5'UTR isoforms (sampling uniformly between $1$ and $6$). 

Subsequently, we sampled randomly the length of the 5'UTR for each isoform. In this case, we sample from the distribution of all 5'UTR lengths identified by Pelechano et al. \cite{Pelechano2013}. To obtain a parametric distribution of this data, we used the python package \textit{fitter} to iterate through multiple candidate distributions and fit them to the data. We selected a gamma distribution which gave the best fit. 

The next step in this process is generating an underlying distribution for the newly generated isoforms. To accomplish this we generate random weights for each one of the isoforms. Taking the ratio of each individual weight to the total weight of the isoforms gives a relative abundance for each isoform. This method imposes some restrictions on the number of isoforms. Often, as seen in the Pelechano data, a gene will have hundreds of isoforms, out of which only a small number will be frequent. Generating too many isoforms for a gene risks having very low relative frequency among them, making the transition between isoforms indistinguishable from random noise. Therefore, for the first model we decided to generate up to $6$ isoforms for each gene. This often results in different distributions ($1$ dominant isoform and some infrequent isoforms up to isoforms equally distributed). Additionally, the low number of isoforms minimizes the chance that isoform junctions are clustered together. For potential variations of this model, see the Discussion section (\ref{disc}).

Finally, we randomise the number of reads we see across all isoforms of a gene. Given the underlying isoform distribution, it is easy to compute how many reads come from each isoform. Thus, the generation problem is reduced to generating a fixed number of reads (intervals) that are fully contained in an annotated region (the isoform - also an interval). Again, we employ a naive approach to this problem. We fix the read length based on the average read length in our mRNA experiments (44 nt) and we sample $n$ points from the large interval as the beginning of each read. The end points of each read are $length$ base pairs further downstream from the beginning. In this process, one has to pay attention not to generate reads that fall outside of the isoform boundaries. Section \ref{disc} contains an example of a more sophisticated method for read generation.  

This subpipeline for data generation has multiple parameters that can be varied and because its random nature, each dataset is different. Therefore, obtaining large amounts of data for classifier training is very feasible. To verify our hypothesis holds on this data too, we employed the same metagene analysis (Section \ref{metagene_sect}) we used for our RNASeq data.  

\subsection{Machine Learning Models}
\subsubsection{Choice of model}
Why not a simple NN, why not unsupervised learning, why RNN in the end. 
\subsubsection{Dataset \& Feature definition}
\subsubsection{Model Design}
\subsubsection{Training and parameter tuning}
\subsubsection{variations}

[@caitken \& @astanciu can we double check all the information in this section?]


\section{Results}\label{res}
\subsection{Preliminary Results}
In order to build more confidence in our intuition, we queried the entire genome for patterns that show easily identifiable isoform junctions. Figure \ref{interesting_genes} show four genes that present visible increases in read densities. 
Additionally, we took all the annotated isoform junctions annotated by Pelechano et al. \cite{Pelechano2013} and we constructed a metagene plot around all the identified junctions. The predicted increase in cumulative read densities can be seen in Figure \ref{large_metagene}. It is possible 

\subsubsection{Hypothesis Testing}

As described in the previous subsection, we simulated 

\section{Discussion}\label{disc}
\subsection{Data Generation}
\begin{enumerate}
    \item Different Sampling distributions 
    \item Read length variation 
    \item Bayesian learning for different parameters
    \item Unsupervised learning for reproducing different patterns and co dependencies of the variables
    \item Generating UTR lengths given the gene length
    \item Generating the number of reads in a gene given empirical data / using modern tools from differnt authors
\end{enumerate}

\section{Pipeline Usage}

\section{Links}
\begin{enumerate}
    \item  \url{https://github.com/shobe98/Thesis-Text}
\item \url{https://github.com/shobe98/bio-thesis}

\end{enumerate}


\section{Proposal - Introduction}


Sequencing DNA has been one of the most impactful discoveries of the past century. With the recent advances \cite{Ingolia2012} in sequencing speed and availability, biologists are turning more and more to computational tools to analyze large data sets covering entire genomes. \gls{rnaseq} has become a widespread and accessible tool for scientists who are pushing the frontiers of science. [some intro aboyt the prep] After a library is prepared in the lab, all the \gls{mrna} present in the cells gets broken down into tinier fragments. \acrshort{rnaseq} reports with single nucleotide precision all these fragments. These fragments become digital reads represented as strings of A, C, G, T/U characters, and are subsequently aligned to the genome (digitally represented as large text files using the same encoding of nucleobases as above). The genome itself is divided in genes which are well annotated {\tiny[TODO: reference to annotations of the yeast genome]}. Each gene consists of three regions: 5’ \gls{utr}, \gls{cds} and 3’\acrshort{utr}. While the \acrshort{cds} is the region that gets translated into protein, the \acrshort{utr}s play an important role in regulation and translation. Many genes are known to have various isoforms - slight variation in length or in splicing - especially in more complex organisms. Understanding these variety of these isoforms could help us gain a more in depth understanding on regulatory mechanisms. For instance, a recent study \cite{Shamir2020} showed that 
the relative distribution of two isoforms of STAT3 directly influences the expression of a gene correlated with COVID-19 infection. 

While there is significant research in analysing specific protein isoforms, the current methods of analysing isoforms across the whole genome are limited. \acrshort{rnaseq} holds the potential of making isoform analysis accessible and accurate, without extra lab experimentation needed. The tool proposed in this paper is a digital solution which can be run on old \acrshort{rnaseq} experiments, conveying new insights.

Our chosen model organism for implementing and testing isoform prediction is Sacharomyces Cerevisiae, since it is extensively studied and many genes in more complex organisms have homologs in yeast. Scientists have often assumed that for each gene the divisions between the three regions (5'\acrshort{utr}, \acrshort{cds}, 3'\acrshort{utr}) are fixed. contrary to what was previously believed, Pelechano and Steinmetz \cite{Pelechano2013} have shown that S. cerevisiae presents an extensive level of heterogeneity in its transcriptome. In simpler terms, there is variability in the lengths of the 5’UTR and the 3’UTR (i.e. they have multiple isoforms). Thus, in the case of RNASeq experiments, it is nontrivial to know from which isoform each short read comes, especially given that these isoforms are present in various distributions under different conditions. 

It is worth mentioning that there are some alternative methods for identifying isoforms. For instance, UNAGI\cite{Alkadi2020} outperforms the Illumina pipeline when it comes to identifying novel transcripts and does slightly better when it comes to identifying isoforms. Both Alkadi et al. \cite{Alkadi2020} and Pelechano et al. \cite{Pelechano2013} require long reads of cDNA - a more complicated library preparation than the one needed for \acrshort{rnaseq}.

The study poses this question: What is the distribution of transcribed 5’UTR isoforms in an RNASeq experiment, given the findings of Pelechano and Steinmetz \cite{Pelechano2013}? To answer this, we propose developing a tool that takes any \acrshort{rnaseq} dataset together with the Pelechano annotations and outputs the relative distribution of each \acrshort{mrna} isoform. 

{\tiny [Papers for later review]} \cite{Kim2009} \cite{Lee2002} \cite{ReixachsSol2020} \cite{Thorrez2008} 

\section{Proposal - Methods}\label{methods}


{\tiny[MAYBE]}
Running some of our experiments on Ribosome footprint data could provide more insights into the positions of isoform boundaries.

\subsection{Tools}\label{tools}
{\tiny[TODO: find references for tools and libraries]}

Pre-processing the \acrshort{rnaseq} data is a critical step for our experiments. The pipeline used to filter the reads and align them to the genome was created by Ingolia et al. \cite{Ingolia2012} and it uses \textit{fastx\_toolkit} and \textit{bowtie}. The isoform identification tools are written entirely in python3 and use the following libraries to read and plot the data: \textit{pysam, pandas, pybedtools} and \textit{matplotlib}. 

\subsection{Experiments}\label{experiments}
\subsubsection{Metagene Analyisis}\label{metagene}
\acrshort{rnaseq} experiments consist of many short reads (intervals) that align with a gene (are included in a larger interval). Thus, it is important to be able to view read densities - how many reads have aligned to each individual nucleotide - over intervals of interest (often genes, or annotated isoforms). {\tiny [QUESTION: This is one of our main assumption. should it be moved somewhere else?]} 

Calculating and plotting the read densities for particular genes shows {\tiny [TODO: add a plot]} that \acrshort{rnaseq} data can be very noisy, and that the expected effect is not noticeable even for known isoform junctions. This leads to the next logical question to ask in order to validate (or invalidate) the hypothesis: would considering multiple known isoform junctions at the same time magnify the effect which is otherwise hidden by noise? In order to test this, we developed a visualisation tool that aligns and overlaps the read densities over multiple intervals. The plotted sum of these densities is called a metagene plot. To further investigate our hypothesis, we created a metagene plot of all the known isoform junctions. {\tiny [TODO: add a plot]} These preliminary results lead us to believe the hypothesis has the potential of being true. 

\subsubsection{Random generators \& Simulations}\label{rng}
In order to verify the observed effects we developed and are currently {\tiny [just for proposal]} developing a series of simulators. In a different experiment we looked at the metagene plot of all known isoform junctions. The observed increase in read density after the junction needs to be compared to a similar density calculated around randomly generated junctions.

The first attempt at random generation picked random positions from anywhere inside the genome. This revealed some complexities of random generation. First, it turns out that intergenic space has a significant number of reads, thus any junctions generated in outside annotated genes has the potential of skewing the density. Additionally, the junctions considered for the initial metagene are all residing inside the longest 5'\acrshort{utr} annotated by Pelechano et al. \cite{Pelechano2013}. Thus, a random junction generator should be genome and experiment aware. Therefore, we \textit{will} implement a random junction generator that generates random junctions informed by a set of parameters, which include a genome file, a set of annotations and whether the 
generation should follow any distribution (i.e. junctions proportional to the number of junctions identified by Pelechano et al. \cite{Pelechano2013}). With such a generator we hope to employ statistical tests to infer the likely hood of our hypothesis being true. 

One limiting factor of our datasets is that they do not include any a priori knowledge of isoform distributions. Thus, our next goal is to implement a simulation of \acrshort{rnaseq} that takes into account isoform distributions. Thus, such a simulation will start from a genome file and will generate random reads inside of all genes, proportional to weights assigned to each gene. This way, our simulation takes into account the varying levels of expression for each gene. Additionally, we hope to generate a fictional isoform database which informs the relative distributions of each gene. Subsequently, this database will serve to improve our simulation, generating an \acrshort{rnaseq} experiment for a known isoform distribution. 

\subsubsection{Isoform Predictions}\label{prediction}
The tools mentioned above should inform and provide data to subsequent isoform prediction and identification tools. 



\newacronym{rnaseq}{RNASeq}{RNA Sequencing}
\newacronym{mrna}{mRNA}{Messenger RNA}
\newacronym{cds}{CDS}{Coding Sequence}
\newacronym{utr}{UTR}{Untranslated Region}
\newacronym{orf}{ORF}{Open Reading Frame}


\printglossary[type=\acronymtype,title=Abbreviations]



\bibliography{sp}
\bibliographystyle{ieeetr}

{\tiny [TODO: Find a way to properly reference the papers in the text] }

\end{document}



